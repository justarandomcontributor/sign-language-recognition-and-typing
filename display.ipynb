{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os \n",
    "\n",
    "class_names = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4',\n",
    "               5: '5', 6: '6', 7: '7', 8: '8', 9: '9',\n",
    "               10: 'a', 11: 'b', 12: 'c', 13: 'd', 14: 'e',\n",
    "               15: 'f', 16: 'g', 17: 'h', 18: 'i', 19: 'k',\n",
    "               20: 'l', 21: 'm', 22: 'n', 23: 'o', 24: 'p',\n",
    "               25: 'q', 26: 'r', 27: 's', 28: 't', 29: 'u',\n",
    "               30: 'v', 31: 'w', 32: 'x', 33: 'y'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to stack windows horizontally or vertically \n",
    "# taken from https://youtu.be/WQeoO7MI0Bs also can refer to the link in the video description\n",
    "\n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be used to reset the GPU if required\n",
    "\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# gap to prevent confusion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "with tf.device('GPU:0'):\n",
    "    # Using VGG19 model with Imagenet weights to extract features from the images for faster and better results.\n",
    "\n",
    "    base_model = VGG19(include_top=False, weights='imagenet', input_shape=(136,260,3))\n",
    "\n",
    "    for layer in base_model.layers:    # freezing the base_model layers\n",
    "        layer.trainable= False\n",
    "\n",
    "    # base_model.summary()\n",
    "\n",
    "    last_output = base_model.output\n",
    "\n",
    "    x = layers.Flatten()(last_output)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)                \n",
    "    x = layers.Dense(34, activation='softmax')(x)    # number of neurons to be changed depending upon number of output classes       \n",
    "\n",
    "    model = Model( base_model.input, x) \n",
    "\n",
    "    model.compile(optimizer ='adam', \n",
    "                  loss = 'categorical_crossentropy', \n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.load_weights('C:/Users/sinha/Desktop/Open cv/total_dataset_89/model_total_dataset_89.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 240, 460, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 120, 230, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 120, 230, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 120, 230, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 120, 230, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 120, 230, 32) 128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 120, 230, 32) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 120, 230, 32) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 120, 230, 16) 512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 120, 230, 16) 64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 120, 230, 16) 144         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 120, 230, 16) 64          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 120, 230, 16) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 16)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 16)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 4)      68          block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 16)     80          block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 120, 230, 16) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 120, 230, 16) 256         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 120, 230, 16) 64          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (FixedDropout)     (None, 120, 230, 16) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 120, 230, 16) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 120, 230, 96) 1536        block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 120, 230, 96) 384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 120, 230, 96) 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 60, 115, 96)  864         block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 60, 115, 96)  384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 60, 115, 96)  0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 60, 115, 96)  0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 60, 115, 24)  2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 60, 115, 24)  96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 60, 115, 144) 3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 60, 115, 144) 576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 60, 115, 144) 0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 60, 115, 144) 1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 60, 115, 144) 576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 60, 115, 144) 0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 60, 115, 144) 0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 60, 115, 24)  3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 60, 115, 24)  96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (FixedDropout)     (None, 60, 115, 24)  0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 60, 115, 24)  0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 60, 115, 144) 3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 60, 115, 144) 576         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 60, 115, 144) 0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 60, 115, 144) 1296        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 60, 115, 144) 576         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 60, 115, 144) 0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 144)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 60, 115, 144) 0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 60, 115, 24)  3456        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 60, 115, 24)  96          block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (FixedDropout)     (None, 60, 115, 24)  0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 60, 115, 24)  0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 60, 115, 144) 3456        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 60, 115, 144) 576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 60, 115, 144) 0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 30, 58, 144)  3600        block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 30, 58, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 30, 58, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 30, 58, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 30, 58, 48)   6912        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 30, 58, 48)   192         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 30, 58, 288)  13824       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 30, 58, 288)  1152        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 30, 58, 288)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 30, 58, 288)  7200        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 30, 58, 288)  1152        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 30, 58, 288)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 288)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 30, 58, 288)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 30, 58, 48)   13824       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 30, 58, 48)   192         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (FixedDropout)     (None, 30, 58, 48)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 30, 58, 48)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 30, 58, 288)  13824       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 30, 58, 288)  1152        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 30, 58, 288)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 30, 58, 288)  7200        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 30, 58, 288)  1152        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 30, 58, 288)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 288)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 30, 58, 288)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 30, 58, 48)   13824       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 30, 58, 48)   192         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (FixedDropout)     (None, 30, 58, 48)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 30, 58, 48)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 30, 58, 288)  13824       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 30, 58, 288)  1152        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 30, 58, 288)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 15, 29, 288)  2592        block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 15, 29, 288)  1152        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 15, 29, 288)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 288)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 15, 29, 288)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 15, 29, 88)   25344       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 15, 29, 88)   352         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 15, 29, 528)  46464       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 15, 29, 528)  2112        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 15, 29, 528)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 15, 29, 528)  4752        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 15, 29, 528)  2112        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 15, 29, 528)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 528)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 528)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 22)     11638       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 528)    12144       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 15, 29, 528)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 15, 29, 88)   46464       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 15, 29, 88)   352         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (FixedDropout)     (None, 15, 29, 88)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 15, 29, 88)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 15, 29, 528)  46464       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 15, 29, 528)  2112        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 15, 29, 528)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 15, 29, 528)  4752        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 15, 29, 528)  2112        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 15, 29, 528)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 528)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 528)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 22)     11638       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 528)    12144       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 15, 29, 528)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 15, 29, 88)   46464       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 15, 29, 88)   352         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (FixedDropout)     (None, 15, 29, 88)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 15, 29, 88)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 15, 29, 528)  46464       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 15, 29, 528)  2112        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 15, 29, 528)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 15, 29, 528)  4752        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 15, 29, 528)  2112        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 15, 29, 528)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 528)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 528)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 22)     11638       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 528)    12144       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 15, 29, 528)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 15, 29, 88)   46464       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 15, 29, 88)   352         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (FixedDropout)     (None, 15, 29, 88)   0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 15, 29, 88)   0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 15, 29, 528)  46464       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 15, 29, 528)  2112        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 15, 29, 528)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 15, 29, 528)  13200       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 15, 29, 528)  2112        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 15, 29, 528)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 528)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 528)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 22)     11638       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 528)    12144       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 15, 29, 528)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 15, 29, 120)  63360       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 15, 29, 120)  480         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 15, 29, 720)  86400       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 15, 29, 720)  2880        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 15, 29, 720)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 15, 29, 720)  18000       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 15, 29, 720)  2880        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 15, 29, 720)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 720)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 720)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 30)     21630       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 720)    22320       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 15, 29, 720)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 15, 29, 120)  86400       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 15, 29, 120)  480         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (FixedDropout)     (None, 15, 29, 120)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 15, 29, 120)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 15, 29, 720)  86400       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 15, 29, 720)  2880        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 15, 29, 720)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 15, 29, 720)  18000       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 15, 29, 720)  2880        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 15, 29, 720)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 720)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 720)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 30)     21630       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 720)    22320       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 15, 29, 720)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 15, 29, 120)  86400       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 15, 29, 120)  480         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (FixedDropout)     (None, 15, 29, 120)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 15, 29, 120)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 15, 29, 720)  86400       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 15, 29, 720)  2880        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 15, 29, 720)  0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 15, 29, 720)  18000       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 15, 29, 720)  2880        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 15, 29, 720)  0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 720)          0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 720)    0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 30)     21630       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 720)    22320       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 15, 29, 720)  0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 15, 29, 120)  86400       block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 15, 29, 120)  480         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (FixedDropout)     (None, 15, 29, 120)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 15, 29, 120)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 15, 29, 720)  86400       block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 15, 29, 720)  2880        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 15, 29, 720)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 8, 15, 720)   18000       block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 8, 15, 720)   2880        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 8, 15, 720)   0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 720)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 720)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 30)     21630       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 720)    22320       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 8, 15, 720)   0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 8, 15, 208)   149760      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 8, 15, 208)   832         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 8, 15, 1248)  259584      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 8, 15, 1248)  4992        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 8, 15, 1248)  0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 8, 15, 1248)  31200       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 8, 15, 1248)  4992        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 8, 15, 1248)  0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1248)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1248)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 52)     64948       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1248)   66144       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 8, 15, 1248)  0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 8, 15, 208)   259584      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 8, 15, 208)   832         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (FixedDropout)     (None, 8, 15, 208)   0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 8, 15, 208)   0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 8, 15, 1248)  259584      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 8, 15, 1248)  4992        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 8, 15, 1248)  0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 8, 15, 1248)  31200       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 8, 15, 1248)  4992        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 8, 15, 1248)  0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1248)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1248)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 52)     64948       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1248)   66144       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 8, 15, 1248)  0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 8, 15, 208)   259584      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 8, 15, 208)   832         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (FixedDropout)     (None, 8, 15, 208)   0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 8, 15, 208)   0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 8, 15, 1248)  259584      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 8, 15, 1248)  4992        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 8, 15, 1248)  0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 8, 15, 1248)  31200       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 8, 15, 1248)  4992        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 8, 15, 1248)  0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1248)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1248)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 52)     64948       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1248)   66144       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 8, 15, 1248)  0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 8, 15, 208)   259584      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 8, 15, 208)   832         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (FixedDropout)     (None, 8, 15, 208)   0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 8, 15, 208)   0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 8, 15, 1248)  259584      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 8, 15, 1248)  4992        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 8, 15, 1248)  0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 8, 15, 1248)  31200       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 8, 15, 1248)  4992        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 8, 15, 1248)  0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1248)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1248)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 52)     64948       block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1248)   66144       block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 8, 15, 1248)  0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 8, 15, 208)   259584      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 8, 15, 208)   832         block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (FixedDropout)     (None, 8, 15, 208)   0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 8, 15, 208)   0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 8, 15, 1248)  259584      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 8, 15, 1248)  4992        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 8, 15, 1248)  0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 8, 15, 1248)  11232       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 8, 15, 1248)  4992        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 8, 15, 1248)  0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1248)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1248)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 52)     64948       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1248)   66144       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 8, 15, 1248)  0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 8, 15, 352)   439296      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 8, 15, 352)   1408        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 8, 15, 2112)  743424      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 8, 15, 2112)  8448        block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 8, 15, 2112)  0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 8, 15, 2112)  19008       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 8, 15, 2112)  8448        block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 8, 15, 2112)  0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 2112)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 2112)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 88)     185944      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 2112)   187968      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 8, 15, 2112)  0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 8, 15, 352)   743424      block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 8, 15, 352)   1408        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (FixedDropout)     (None, 8, 15, 352)   0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 8, 15, 352)   0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 8, 15, 1408)  495616      block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 8, 15, 1408)  5632        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 8, 15, 1408)  0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 168960)       0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          21627008    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 34)           2210        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 29,406,036\n",
      "Trainable params: 21,637,474\n",
      "Non-trainable params: 7,768,562\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from efficientnet import tfkeras as efn\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "base_model = efn.EfficientNetB2(input_shape = (240, 460, 3), include_top = False, weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:    # freezing the base_model layers\n",
    "    layer.trainable= False\n",
    "    \n",
    "# base_model.summary()\n",
    "\n",
    "last_output = base_model.output\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)                \n",
    "x = layers.Dense(34, activation='softmax')(x)    # number of neurons to be changed depending upon number of output classes       \n",
    "\n",
    "model = Model( base_model.input, x) \n",
    "\n",
    "model.compile(optimizer ='adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.load_weights('efficientnetb2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.07610334\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686 0.02799686\n",
      " 0.02799686 0.02799686 0.02799686 0.02799686], shape=(34,), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1a221c757352>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m480\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m240\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m480\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Create a batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # 0 for laptop webcam and 1 for external webcam\n",
    "\n",
    "while True:\n",
    "    suc, img = cap.read()\n",
    "\n",
    "#     width = 260\n",
    "#     height = 136\n",
    "#     dim = (width, height)\n",
    "\n",
    "    # resize image\n",
    "#     resized = cv2.resize(img[0:240,20:260], dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "#     cv2.rectangle(img,(20,0),(260,240),(0,255,0),3)\n",
    "\n",
    "    cv2.rectangle(img,(20,0),(480,240),(0,255,0),3)\n",
    "    \n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img[0:240,20:480])\n",
    "    img_array = tf.expand_dims(img_array, 0)   # Create a batch\n",
    "    \n",
    "    with tf.device('/CPU:0'):\n",
    "        predictions = model.predict(img_array)\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "        print(score)\n",
    "\n",
    "    cv2.putText(img, class_names[np.argmax(score)], (50,50), cv2.FONT_HERSHEY_SIMPLEX , 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    imgStack = stackImages(0.6,[img,img[0:240,20:480]])\n",
    "    cv2.imshow(\"Stacked Images\", imgStack)   # displaying the stacked images\n",
    "\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('z'):  # if \"z\" is pressed the close the capture proccess\n",
    "        flag=False\n",
    "        cap.release()\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()  # destroy/close the windows opened by the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
